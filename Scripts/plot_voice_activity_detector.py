# -*- coding: utf-8 -*-
"""Plot voice activity detector.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zBeWNfPmaoPy54lXIFUT-WTkOhPgi50C
"""

!pip install webrtcvad
import librosa
import pandas as pd
import numpy as np
import librosa.display
import matplotlib.pyplot as plt
from scipy.signal import get_window1
import librosa.display
import os
import webrtcvad
import csv

def window_frame(y, n_fft=160, hop_length=160, win_length=160, window='hann'):
  fft_window = librosa.filters.get_window(window, win_length, fftbins=True)
  # Pad the window out to n_fft size
  fft_window = librosa.util.pad_center(fft_window, n_fft)
  # Reshape so that the window can be broadcast
  fft_window = fft_window.reshape((-1, 1))
  # Pad the time series so that frames are centered
  y = np.pad(y, int(n_fft // 2), mode='reflect')
  # Window the time series.
  y_frames = librosa.util.frame(y, frame_length=n_fft, hop_length=hop_length)
  windowed_frames = (y_frames * fft_window).T
  return windowed_frames

y, sr = librosa.load("/content/signal.wav", sr = 16000)
win_len = int(sr*0.01)
duration = y.shape[0]/sr
frame = window_frame(y, win_len, win_len, win_len, 'hann')


vad = webrtcvad.Vad(3)
Labely = []
SR = 16000
for fra in frame:
    fr = np.int16(fra * 32768).tobytes() #change float to bytes
    is_Speech = vad.is_speech(fr, SR)
    if (is_Speech):
      Labely.append(1)
    else:
      Labely.append(0)

fig, ax = plt.subplots(nrows=2, sharex=True, sharey=False)
librosa.display.waveplot(y, sr=sr, ax=ax[0])
index = [0.01*x for x in range(len(frame))]
plt.plot(index, Labely, c = 'r')